{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "continued-geology",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting and Filtering Clips\n",
      "Complete!                \n",
      "\n",
      "Extracting Features\n",
      "Complete!                \n",
      "\n",
      "Normalizing Features\n",
      "Complete!                \n",
      "\n",
      "Combining Data\n",
      "Complete!                \n",
      "\n",
      "Splitting and Padding Audio\n",
      "Complete!                \n",
      "\n",
      "Saving Images\n",
      "Complete!                     \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import librosa\n",
    "import librosa.feature as lf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# normalize by feature\n",
    "def normalize(data,column):\n",
    "    feat_min = scalers[column]['min']\n",
    "    feat_max = scalers[column]['max']\n",
    "    array = data[column].to_numpy()\n",
    "    array = (array-feat_min)/(feat_max-feat_min)\n",
    "    return array\n",
    "\n",
    "def concat(data,columns):\n",
    "    concat_img = pd.DataFrame(columns=['track','final'])\n",
    "    for index in data.index:\n",
    "        for column in columns:\n",
    "            entry = data.loc[index][column]\n",
    "            if column == columns[0]:\n",
    "                flat_entry = entry\n",
    "            else:\n",
    "                flat_entry = np.concatenate((flat_entry,entry),axis=0)\n",
    "        concat_img = concat_img.append({'track':index,'final':flat_entry},ignore_index=True)\n",
    "    return concat_img\n",
    "\n",
    "# load the min and max of the training sets for normalizing \n",
    "with open('../Data/Model Config/Scale_Config.json') as f:\n",
    "    scalers = json.load(f)\n",
    "\n",
    "print('Collecting and Filtering Clips')\n",
    "path = 'Audio Clips Here!/'\n",
    "files = os.listdir(path)\n",
    "audio = pd.DataFrame()\n",
    "for count, track in enumerate(files,start=1):\n",
    "    if '.wav' in track:\n",
    "        try:\n",
    "            clip, sample_rate = librosa.load(path+track, sr=16000)\n",
    "        except:\n",
    "            clip, sample_rate = np.nan,np.nan\n",
    "    audio = audio.append({'track_name':track,'audio':clip,'sample_rate':sample_rate},ignore_index=True)\n",
    "    print('%d of %d complete (%d%%)' % (count,len(files),(count/len(files))*100),end='\\r')   \n",
    "audio = audio.set_index('track_name')\n",
    "print('%-25s\\n' % 'Complete!') \n",
    "\n",
    "print(\"Extracting Features\")\n",
    "columns = ['track_name','mel spectrogram','chroma','mel cepstral']\n",
    "features = pd.DataFrame(columns=columns)\n",
    "for count,track in enumerate(audio.index,start=1):\n",
    "    clip = audio.loc[track]['audio']\n",
    "    sample_rate = audio.loc[track]['sample_rate']\n",
    "    try:\n",
    "        L = [track,\n",
    "             # mel-frequency spectrogram\n",
    "             lf.melspectrogram(clip,sample_rate),\n",
    "             # chroma features\n",
    "             lf.chroma_stft(clip,sample_rate),        \n",
    "             # mel-frequency cepstral coefficients\n",
    "             lf.mfcc(clip,sample_rate)]\n",
    "        features = features.append(dict(zip(columns,L)),ignore_index=True)\n",
    "    except:\n",
    "        print('An error has occured on the track \"%s\".' % (track))\n",
    "    print('%d of %d complete (%d%%)' % (count,len(audio.index),(count/len(audio.index))*100)\n",
    "          ,end='\\r')\n",
    "features = features.set_index('track_name')\n",
    "features['mel spectrogram'] = [librosa.power_to_db(entry, ref=np.max) for entry in features['mel spectrogram']]\n",
    "print('%-25s\\n' % 'Complete!') \n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "print('Normalizing Features')\n",
    "for column in features.columns:\n",
    "    features[column] = normalize(features,column)\n",
    "print('%-25s\\n' % 'Complete!') \n",
    "\n",
    "print('Combining Data')\n",
    "final = concat(features,features.columns)\n",
    "final = final.set_index('track')\n",
    "print('%-25s\\n' % 'Complete!') \n",
    "\n",
    "print('Splitting and Padding Audio')\n",
    "clips = pd.DataFrame()\n",
    "max_len=140\n",
    "for index in final.index:\n",
    "    colname = index+'_slice'\n",
    "    img = final.loc[index][0]\n",
    "    array_len = img.shape[1]\n",
    "    if array_len > max_len:\n",
    "        n_slices = array_len//max_len\n",
    "        remainder = array_len%max_len\n",
    "        for n in range(n_slices):\n",
    "            front = n*max_len\n",
    "            back = front+max_len\n",
    "            img_slice = img[:,front:back]\n",
    "            clips = clips.append({colname:img_slice},ignore_index=True)\n",
    "        if remainder != 0:\n",
    "            img_slice = img[:,-remainder:]\n",
    "            zeros = max_len - remainder\n",
    "            front = int(zeros/2)\n",
    "            back = int(zeros-front)\n",
    "            img_slice = np.pad(img_slice, ((0,0),(front,back)))\n",
    "            clips = clips.append({colname:img_slice},ignore_index=True)\n",
    "    if array_len <= max_len:\n",
    "        zeros = max_len - array_len\n",
    "        front = int(zeros/2)\n",
    "        back = int(zeros-front)\n",
    "        img = np.pad(img, ((0,0),(front,back)))\n",
    "        clips = clip.appends({colname:img},ignore_index=True)\n",
    "print('%-25s\\n' % 'Complete!') \n",
    "\n",
    "print('Saving Images')\n",
    "\n",
    "\n",
    "    \n",
    "total_tracks, count = len(clips),1\n",
    "for track in clips.columns:\n",
    "    track_data = clips[track].dropna()\n",
    "    for n,snippet in enumerate(track_data):\n",
    "        path = 'Clip Images/%s__%d.png' % (track[:-10],n)\n",
    "        plt.imsave(path,snippet)\n",
    "        \n",
    "        print('%4d of %d complete (%d%%)' % (count,total_tracks,(count/total_tracks)*100),end='\\r')\n",
    "        count+=1\n",
    "print('%-30s' % ('Complete!')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "loved-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Images:\n",
      "  24 of 24 complete (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import preprocessing\n",
    "\n",
    "# set up X varible (Image Data)\n",
    "X = []\n",
    "y = []\n",
    "print('\\nLoading Images:')\n",
    "folder = os.listdir('Clip Images')\n",
    "for count, file in enumerate(folder,start=1):\n",
    "    image = preprocessing.image.load_img('Clip Images/'+file)\n",
    "    input_arr = preprocessing.image.img_to_array(image)\n",
    "    X.append(input_arr)\n",
    "    y.append(file.split('__')[0])\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(folder),(count/len(folder))*100),end='\\r')\n",
    "print('\\n')\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "with open('../Data/Model Config/Model_Labels.json') as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../Data/Model/Avg_Pool_Split')\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "predictions = pd.DataFrame(predict) \n",
    "predictions.columns = labels.keys()\n",
    "\n",
    "predictions['pred'] = predictions.idxmax(axis=1)\n",
    "predictions['pred'] = predict[column].str.split('_',expand=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
