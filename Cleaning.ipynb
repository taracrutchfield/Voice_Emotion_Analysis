{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "multiple-convention",
   "metadata": {},
   "source": [
    "# Data Cleaning and Wrangling\n",
    "The audio clips used in this project came from [CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D) and [RAVDESS](https://smartlaboratory.org/ravdess/) which are two databases consiting of lines read by actors portryaing specific emotions. These clips were filtered using voice activity detection then converted into numpy arrays to store within the dataframe `Audio Data.csv`. Overall this process saves a csv with the following features:\n",
    "- statment: indicates the phase used for the clip\n",
    "- emotion: intended emotion of audio\n",
    "- audio: numpy array of audio\n",
    "- sampling rate: sampling rate of audio\n",
    "- sex: actor's sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Modules\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import webrtcvad\n",
    "import sounddevice as sd\n",
    "# General Modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-modern",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Audio processing in python is a relativley new thing for me so I \"found inspiration\" (aka tweeked snippets of code) from the projects of others.\n",
    "- Voice activity detection by [John Wiseman](https://github.com/wiseman)\n",
    "- Byte to numpy array conversion by [HudsonHuang](https://gist.github.com/HudsonHuang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "muslim-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        #sys.stdout.write('1' if is_speech else '0')\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                # sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                #sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    #if triggered:\n",
    "    #    sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "    #sys.stdout.write('\\n')\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])\n",
    "\n",
    "def VAD(path,ag=1):\n",
    "    audio, sample_rate = read_wave(path)\n",
    "    vad = webrtcvad.Vad(int(ag))\n",
    "    frames = frame_generator(30, audio, sample_rate)\n",
    "    frames = list(frames)\n",
    "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "    \n",
    "    audio_byte = b\"\".join(segments)\n",
    "    return (audio_byte,sample_rate)\n",
    "\n",
    "def byte_to_float(byte):\n",
    "    # byte -> int16(PCM_16) -> float32\n",
    "    return pcm2float(np.frombuffer(byte,dtype=np.int16), dtype='float32')\n",
    "\n",
    "def pcm2float(sig, dtype='float32'):\n",
    "    \"\"\"Convert PCM signal to floating point with a range from -1 to 1.\n",
    "    Use dtype='float32' for single precision.\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig : array_like\n",
    "        Input array, must have integral type.\n",
    "    dtype : data type, optional\n",
    "        Desired (floating point) data type.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Normalized floating point data.\n",
    "    See Also\n",
    "    --------\n",
    "    float2pcm, dtype\n",
    "    \"\"\"\n",
    "    sig = np.asarray(sig)\n",
    "    if sig.dtype.kind not in 'iu':\n",
    "        raise TypeError(\"'sig' must be an array of integers\")\n",
    "    dtype = np.dtype(dtype)\n",
    "    if dtype.kind != 'f':\n",
    "        raise TypeError(\"'dtype' must be a floating point type\")\n",
    "\n",
    "    i = np.iinfo(sig.dtype)\n",
    "    abs_max = 2 ** (i.bits - 1)\n",
    "    offset = i.min + abs_max\n",
    "    return (sig.astype(dtype) - offset) / abs_max\n",
    "\n",
    "def play(audio_data,n=None):\n",
    "    '''\n",
    "    Plays a random audio clip from a set of audio clips. \n",
    "    Prints the statement number, emotion, and sex of the actor\n",
    "    '''\n",
    "    if n == None:\n",
    "        n=np.random.randint(0,len(audio_data)+1)\n",
    "        \n",
    "    test = audio_data.iloc[n]\n",
    "    print(test.loc[['statment','emotion','sex']])\n",
    "\n",
    "    test_audio = byte_to_float(test['audio'])\n",
    "        \n",
    "    test_f = test['sampling rate']\n",
    "\n",
    "    sd.play(test_audio, test_f)\n",
    "    status = sd.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-alfred",
   "metadata": {},
   "source": [
    "# Unzip Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "creative-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Audio Clips' not in os.listdir():\n",
    "    with zipfile.ZipFile(\"Audio Clips.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-observation",
   "metadata": {},
   "source": [
    "# Collection and VAD\n",
    "Use voice activity detection to remove any background noise and put audio into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "devoted-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440 of 1440 complete (100%)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\xe6\\xff\\xfb\\xff\\xfe\\xff5\\x00\\\\\\x00:\\x00:\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x1d\\x00!\\x00\\x01\\x00\\xe8\\xff\\xff\\xff\\x15\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'E\\x00Q\\x00S\\x00^\\x00f\\x00b\\x00^\\x00]\\x00S\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\r\\xff\\x16\\xff\\x1f\\xff\\x1e\\xff(\\xff9\\xff@\\xf...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\xd3\\xff\\xeb\\xff\\xfa\\xff\\xf9\\xff\\x19\\x00C\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6                                                  7  \\\n",
       "0  3  1  1  1  1  1  1  b'\\xe6\\xff\\xfb\\xff\\xfe\\xff5\\x00\\\\\\x00:\\x00:\\x0...   \n",
       "0  3  1  1  1  1  2  1  b'\\x1d\\x00!\\x00\\x01\\x00\\xe8\\xff\\xff\\xff\\x15\\x0...   \n",
       "0  3  1  1  1  2  1  1  b'E\\x00Q\\x00S\\x00^\\x00f\\x00b\\x00^\\x00]\\x00S\\x0...   \n",
       "0  3  1  1  1  2  2  1  b'\\r\\xff\\x16\\xff\\x1f\\xff\\x1e\\xff(\\xff9\\xff@\\xf...   \n",
       "0  3  1  2  1  1  1  1  b'\\xd3\\xff\\xeb\\xff\\xfa\\xff\\xf9\\xff\\x19\\x00C\\x0...   \n",
       "\n",
       "       8  \n",
       "0  48000  \n",
       "0  48000  \n",
       "0  48000  \n",
       "0  48000  \n",
       "0  48000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_RAVDESS = pd.DataFrame()\n",
    "error = []\n",
    "\n",
    "folder='Audio Clips/RAVDESS/'\n",
    "count = 0\n",
    "for actor in os.listdir(folder):\n",
    "    path = folder+actor+'/'\n",
    "    for track in os.listdir(path):\n",
    "        count+=1\n",
    "        try:\n",
    "            metadata=[int(x) for x in track[:-4].split('-')]\n",
    "            audio_byte,rate = VAD(path+track);\n",
    "            metadata.append(audio_byte)\n",
    "            metadata.append(rate)\n",
    "            data_RAVDESS = data_RAVDESS.append([metadata])\n",
    "        except:\n",
    "            error.append(track)\n",
    "        print('%4d of 1440 complete (%d%%)' % (count,(count/1440)*100),end='\\r')\n",
    "            \n",
    "data_RAVDESS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inner-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7442 of 7442 complete (100%)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>DIS</td>\n",
       "      <td>XX</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>FEA</td>\n",
       "      <td>XX</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>HAP</td>\n",
       "      <td>XX</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>NEU</td>\n",
       "      <td>XX</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2   3                                                  4  \\\n",
       "0  1001  DFA  ANG  XX  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...   \n",
       "0  1001  DFA  DIS  XX  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...   \n",
       "0  1001  DFA  FEA  XX  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...   \n",
       "0  1001  DFA  HAP  XX  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...   \n",
       "0  1001  DFA  NEU  XX  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...   \n",
       "\n",
       "       5  \n",
       "0  16000  \n",
       "0  16000  \n",
       "0  16000  \n",
       "0  16000  \n",
       "0  16000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_CREMA_D = pd.DataFrame()\n",
    "\n",
    "folder='Audio Clips/CREMA_D/'\n",
    "count = 0\n",
    "for track in os.listdir(folder):\n",
    "    path = folder+track\n",
    "    count+=1\n",
    "    try:\n",
    "        metadata=track[:-4].split('_')\n",
    "        audio_byte,rate = VAD(path)\n",
    "        metadata.append(audio_byte)\n",
    "        metadata.append(rate)\n",
    "        data_CREMA_D = data_CREMA_D.append([metadata])\n",
    "    except:\n",
    "        error.append(track)\n",
    "    print('%4d of 7442 complete (%d%%)' % (count,(count/7442)*100),end='\\r')\n",
    "        \n",
    "data_CREMA_D.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-charger",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Clean and combine both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strange-dominant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1435 entries, 0 to 1434\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   emotion        1435 non-null   int64 \n",
      " 1   statment       1435 non-null   int64 \n",
      " 2   actorID        1435 non-null   int64 \n",
      " 3   audio          1435 non-null   object\n",
      " 4   sampling rate  1435 non-null   int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 56.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7442 entries, 0 to 7441\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ActorID        7442 non-null   int32 \n",
      " 1   statment       7442 non-null   object\n",
      " 2   emotion        7442 non-null   object\n",
      " 3   audio          7442 non-null   object\n",
      " 4   sampling rate  7442 non-null   int64 \n",
      "dtypes: int32(1), int64(1), object(3)\n",
      "memory usage: 261.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# change index to a range of ints\n",
    "data_RAVDESS.index = pd.RangeIndex(0,stop = len(data_RAVDESS))\n",
    "data_CREMA_D.index = pd.RangeIndex(0,stop = len(data_CREMA_D))\n",
    "\n",
    "# drop unnecessary columns\n",
    "data_RAVDESS = data_RAVDESS.drop(columns=[0,1,3,5])\n",
    "data_CREMA_D = data_CREMA_D.drop(columns=[3])\n",
    "\n",
    "# rename columns\n",
    "data_RAVDESS.columns=['emotion','statment','actorID','audio','sampling rate']\n",
    "data_CREMA_D.columns=['ActorID','statment','emotion','audio','sampling rate']\n",
    "\n",
    "# make sure id is an int not an object\n",
    "data_CREMA_D[['ActorID']] = data_CREMA_D[['ActorID']].astype('int')\n",
    "\n",
    "data_RAVDESS.info()\n",
    "data_CREMA_D.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-baseline",
   "metadata": {},
   "source": [
    "## Label Convention\n",
    "Make sure that both datasets have the same column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corporate-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all the emotions human redable\n",
    "for i,j in [('ANG','anger'),('DIS','disgust'),('FEA','fear'),('NEU','neutral'),('HAP','happy'),('SAD','sad')]:\n",
    "    data_CREMA_D['emotion'] = data_CREMA_D['emotion'].str.replace(i,j)\n",
    "    \n",
    "for i,j in [(1,'neutral'),(2,'calm'),(3,'happy'),(4,'sad'),(5,'anger'),(6,'fear'),(7,'disgust'),(8,'surprised')]:\n",
    "    data_RAVDESS['emotion'] = data_RAVDESS['emotion'].replace(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "occasional-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor gender\n",
    "CREMA_D = pd.read_csv('CSVs/CREMA_D_Actors.csv',index_col='Unnamed: 0')\n",
    "data_CREMA_D = data_CREMA_D.merge(CREMA_D[['Sex','ActorID']],on='ActorID',how='inner')\n",
    "data_CREMA_D = data_CREMA_D.drop(columns='ActorID').rename(columns={'Sex':'sex'})\n",
    "\n",
    "data_RAVDESS['actorID'] = data_RAVDESS['actorID'] % 2\n",
    "data_RAVDESS['actorID'] = data_RAVDESS['actorID'].replace(1,'Male').replace(0,'Female')\n",
    "data_RAVDESS = data_RAVDESS.rename(columns={'actorID':'sex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coral-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the statement convention\n",
    "for i,j in enumerate(data_CREMA_D['statment'].unique(),start=3):\n",
    "    data_CREMA_D['statment'] = data_CREMA_D['statment'].replace(j,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-tract",
   "metadata": {},
   "source": [
    "Overall there are 14 total statements used:\n",
    "\n",
    "- 1: Kids are talking by the door.\n",
    "- 2: Dogs are sitting by the door.\n",
    "- 3: Don't forget a jacket.\n",
    "- 4: It's eleven o'clock.\n",
    "- 5: I'm on my way to the meeting.\n",
    "- 6: I think I have a doctor's appointment.\n",
    "- 7 I think I've seen this before.\n",
    "- 8: I would like a new alarm clock.\n",
    "- 9: I wonder what this is about.\n",
    "- 10: Maybe tomorrow it will be cold.\n",
    "- 11: The airplane is almost full.\n",
    "- 12: That is exactly what happened.\n",
    "- 13: The surface is slick.\n",
    "- 14: We'll stop in a couple of minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-drill",
   "metadata": {},
   "source": [
    "## Final Check\n",
    "Make sure the columns and column labels are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unusual-sherman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>audio</th>\n",
       "      <th>sampling rate</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statment  emotion                                              audio  \\\n",
       "0         3    anger  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...   \n",
       "1         3  disgust  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...   \n",
       "2         3     fear  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...   \n",
       "3         3    happy  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...   \n",
       "4         3  neutral  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...   \n",
       "\n",
       "   sampling rate   sex  \n",
       "0          16000  Male  \n",
       "1          16000  Male  \n",
       "2          16000  Male  \n",
       "3          16000  Male  \n",
       "4          16000  Male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_CREMA_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-active",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>statment</th>\n",
       "      <th>sex</th>\n",
       "      <th>audio</th>\n",
       "      <th>sampling rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\xe6\\xff\\xfb\\xff\\xfe\\xff5\\x00\\\\\\x00:\\x00:\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\x1d\\x00!\\x00\\x01\\x00\\xe8\\xff\\xff\\xff\\x15\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'E\\x00Q\\x00S\\x00^\\x00f\\x00b\\x00^\\x00]\\x00S\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\r\\xff\\x16\\xff\\x1f\\xff\\x1e\\xff(\\xff9\\xff@\\xf...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\xd3\\xff\\xeb\\xff\\xfa\\xff\\xf9\\xff\\x19\\x00C\\x0...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion  statment   sex                                              audio  \\\n",
       "0  neutral         1  Male  b'\\xe6\\xff\\xfb\\xff\\xfe\\xff5\\x00\\\\\\x00:\\x00:\\x0...   \n",
       "1  neutral         1  Male  b'\\x1d\\x00!\\x00\\x01\\x00\\xe8\\xff\\xff\\xff\\x15\\x0...   \n",
       "2  neutral         2  Male  b'E\\x00Q\\x00S\\x00^\\x00f\\x00b\\x00^\\x00]\\x00S\\x0...   \n",
       "3  neutral         2  Male  b'\\r\\xff\\x16\\xff\\x1f\\xff\\x1e\\xff(\\xff9\\xff@\\xf...   \n",
       "4     calm         1  Male  b'\\xd3\\xff\\xeb\\xff\\xfa\\xff\\xf9\\xff\\x19\\x00C\\x0...   \n",
       "\n",
       "   sampling rate  \n",
       "0          48000  \n",
       "1          48000  \n",
       "2          48000  \n",
       "3          48000  \n",
       "4          48000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_RAVDESS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "endangered-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data together\n",
    "data = data_CREMA_D.append(data_RAVDESS)\n",
    "data.index = pd.RangeIndex(0,len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coral-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8877 of 8877 complete (100%)\r"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for i in range(len(data)):\n",
    "    path = 'Clean Audio/Clip_%04d.wav' % (i)\n",
    "    audio = data.iloc[i]['audio']\n",
    "    sample_rate = data.iloc[i]['sampling rate']\n",
    "    write_wave(path, audio, sample_rate)\n",
    "    print('%4d of 8877 complete (%d%%)' % (count,(count/8877)*100),end='\\r')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "closed-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a csv\n",
    "data = data.drop(columns=['audio'])\n",
    "data.to_csv('CSVs/Audio Data.csv')\n",
    "\n",
    "# zip clean audio\n",
    "zipfile.ZipFile('Clean Audio.zip', mode='w').write('Clean Audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-signal",
   "metadata": {},
   "source": [
    "### Example Clip\n",
    "uncomment the code below to play a random audio clip from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
