{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-document",
   "metadata": {},
   "source": [
    "# Audio Cleaning\n",
    "With my handy new legend, I can easily go and select all the audio clips I want. Iâ€™ll be applying a voice activity detection filter (VAD) on each clip to help remove some of the background sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elect-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Modules\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import webrtcvad\n",
    "import sounddevice as sd\n",
    "# General Modules\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-minute",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Audio processing in python is a relativley new thing for me so I \"found inspiration\" (aka tweeked snippets of code) from the projects of others.\n",
    "- VAD by [John Wiseman](https://github.com/wiseman)\n",
    "- Byte to numpy array conversion by [HudsonHuang](https://gist.github.com/HudsonHuang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infectious-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        #sys.stdout.write('1' if is_speech else '0')\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                # sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                #sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    #if triggered:\n",
    "    #    sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "    #sys.stdout.write('\\n')\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])\n",
    "\n",
    "def VAD(path,ag=1):\n",
    "    audio, sample_rate = read_wave(path)\n",
    "    vad = webrtcvad.Vad(int(ag))\n",
    "    frames = frame_generator(30, audio, sample_rate)\n",
    "    frames = list(frames)\n",
    "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "    \n",
    "    audio_byte = b\"\".join(segments)\n",
    "    return (audio_byte,sample_rate)\n",
    "\n",
    "def byte_to_float(byte):\n",
    "    # byte -> int16(PCM_16) -> float32\n",
    "    return pcm2float(np.frombuffer(byte,dtype=np.int16), dtype='float32')\n",
    "\n",
    "def pcm2float(sig, dtype='float32'):\n",
    "    \"\"\"Convert PCM signal to floating point with a range from -1 to 1.\n",
    "    Use dtype='float32' for single precision.\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig : array_like\n",
    "        Input array, must have integral type.\n",
    "    dtype : data type, optional\n",
    "        Desired (floating point) data type.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Normalized floating point data.\n",
    "    See Also\n",
    "    --------\n",
    "    float2pcm, dtype\n",
    "    \"\"\"\n",
    "    sig = np.asarray(sig)\n",
    "    if sig.dtype.kind not in 'iu':\n",
    "        raise TypeError(\"'sig' must be an array of integers\")\n",
    "    dtype = np.dtype(dtype)\n",
    "    if dtype.kind != 'f':\n",
    "        raise TypeError(\"'dtype' must be a floating point type\")\n",
    "\n",
    "    i = np.iinfo(sig.dtype)\n",
    "    abs_max = 2 ** (i.bits - 1)\n",
    "    offset = i.min + abs_max\n",
    "    return (sig.astype(dtype) - offset) / abs_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-pathology",
   "metadata": {},
   "source": [
    "# Collection and VAD\n",
    "Grab the audio clips and apply VAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaningful-poker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8690 entries, 0 to 8689\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   path      8690 non-null   object\n",
      " 1   original  8690 non-null   object\n",
      " 2   statment  8690 non-null   int64 \n",
      " 3   emotion   8690 non-null   object\n",
      " 4   sex       8690 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 407.3+ KB\n"
     ]
    }
   ],
   "source": [
    "legend = pd.read_csv('Data/CSVs/Audio Legend Raw.csv',index_col='Unnamed: 0')\n",
    "legend.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "large-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8690 of 8690 complete (100%)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              original                                              audio  \\\n",
       "0  1001_DFA_ANG_XX.wav  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...   \n",
       "0  1001_DFA_DIS_XX.wav  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...   \n",
       "0  1001_DFA_FEA_XX.wav  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...   \n",
       "0  1001_DFA_HAP_XX.wav  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...   \n",
       "0  1001_DFA_NEU_XX.wav  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...   \n",
       "\n",
       "   sample rate  \n",
       "0      16000.0  \n",
       "0      16000.0  \n",
       "0      16000.0  \n",
       "0      16000.0  \n",
       "0      16000.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to save everything in\n",
    "audio = pd.DataFrame()\n",
    "\n",
    "count=1\n",
    "for index in legend.index:\n",
    "    entry = legend.loc[index]\n",
    "    track = entry['original']\n",
    "    path = entry['path']\n",
    "    try:\n",
    "        audio_byte,rate = VAD(path+track)\n",
    "        # if audio_byte is empty, try less rigorous VAD\n",
    "        if audio_byte == b'':\n",
    "            audio_byte,rate = VAD(path+track,ag=0)\n",
    "            # if its still empty, input nan\n",
    "            if audio_byte == b'':\n",
    "                audio_byte,rate = np.nan,np.nan\n",
    "    except:\n",
    "        audio_byte,rate = np.nan,np.nan\n",
    "    audio = audio.append([[track,audio_byte,rate]])\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(legend),(count/len(legend))*100),end='\\r')\n",
    "    count+=1\n",
    "    \n",
    "audio.columns = ['original','audio','sample rate']\n",
    "audio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-brick",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Merge audio with the legend and drop any clips that seem to be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lonely-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8690 entries, 0 to 8689\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   path         8690 non-null   object \n",
      " 1   original     8690 non-null   object \n",
      " 2   statment     8690 non-null   int64  \n",
      " 3   emotion      8690 non-null   object \n",
      " 4   sex          8690 non-null   object \n",
      " 5   audio        8651 non-null   object \n",
      " 6   sample rate  8651 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 543.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = legend.merge(audio,on='original')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-speaker",
   "metadata": {},
   "source": [
    "Check for the tracks that didn't make it through VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "novel-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 tracks couldnt be filtered\n",
      "\n",
      "Emotions\n",
      "sad        30\n",
      "disgust     3\n",
      "neutral     3\n",
      "fear        2\n",
      "happy       1\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Actor Gender\n",
      "Female    25\n",
      "Male      14\n",
      "Name: sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tracks_na = data[data['audio'].isna()]\n",
    "print('%d tracks couldnt be filtered\\n' % len(tracks_na))\n",
    "print('Emotions')\n",
    "print(tracks_na['emotion'].value_counts())\n",
    "print('\\nActor Gender')\n",
    "print(tracks_na['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-mileage",
   "metadata": {},
   "source": [
    "Taking a look at some of these tracks, it appears that the voices in the audio clips were too quiet to pick up. This seems to be most common in the `sad` voice clips, with a majority of the actors being women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arbitrary-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8651 entries, 0 to 8689\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   path         8651 non-null   object \n",
      " 1   original     8651 non-null   object \n",
      " 2   statment     8651 non-null   int64  \n",
      " 3   emotion      8651 non-null   object \n",
      " 4   sex          8651 non-null   object \n",
      " 5   audio        8651 non-null   object \n",
      " 6   sample rate  8651 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 540.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(tracks_na.index)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-truth",
   "metadata": {},
   "source": [
    "While I started with 8877 total clips, wrangling and filtering lowered the total to 8651. Now to save all the clean audio clips and save everything in a new legend. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-allen",
   "metadata": {},
   "source": [
    "# Save Files\n",
    "Save all the clean audio clips in the folder `Clean Audio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mathematical-challenge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8651 of 8651 complete (100%)\r"
     ]
    }
   ],
   "source": [
    "filenames=pd.DataFrame()\n",
    "count = 1\n",
    "for index in data.index:\n",
    "    entry = data.loc[index]\n",
    "    # Save each file with the legend index as the new filename\n",
    "    new_name = 'Clip_%04d.wav' % (index)\n",
    "    path = 'Data/Audio/Clean/'+new_name\n",
    "    filenames = filenames.append([[entry['original'],new_name]])\n",
    "    write_wave(path,entry['audio'],entry['sample rate'])\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(data.index),(count/len(data.index))*100),end='\\r')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-estate",
   "metadata": {},
   "source": [
    "Merge the new filenames with the old filenames and save as the new legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "successful-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize filenames\n",
    "filenames.columns = ['original','filename']\n",
    "# and merge on the old names\n",
    "new_legend = legend.merge(filenames,how='left',on='original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect now save!\n",
    "new_legend.to_csv('Data/CSVs/Audio Legend Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-planner",
   "metadata": {},
   "source": [
    "### Example Clip\n",
    "Play a random audio clip from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "removable-carroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original    1010_IEO_NEU_XX.wav\n",
      "statment                      4\n",
      "emotion                 neutral\n",
      "sex                      Female\n",
      "Name: 743, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# select a random clip\n",
    "n = np.random.permutation(data.index)[0]\n",
    "example = data.loc[n]\n",
    "\n",
    "# print info about the clip\n",
    "print(example.loc[['original','statment','emotion','sex']])\n",
    "\n",
    "# play audio\n",
    "example_audio = byte_to_float(example['audio'])\n",
    "example_srate = example['sample rate']\n",
    "sd.play(example_audio, example_srate)\n",
    "status = sd.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
