{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nervous-venture",
   "metadata": {},
   "source": [
    "# Audio Cleaning\n",
    "With my handy new legend, I can easily go and select all the audio clips I want. Iâ€™ll be applying a voice activity detection filter (VAD) on each clip to help remove some of the background sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "immune-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Modules\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import webrtcvad\n",
    "import sounddevice as sd\n",
    "# General Modules\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-assets",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Audio processing in python is a relativley new thing for me so I \"found inspiration\" (aka tweeked snippets of code) from the projects of others.\n",
    "- VAD by [John Wiseman](https://github.com/wiseman)\n",
    "- Byte to numpy array conversion by [HudsonHuang](https://gist.github.com/HudsonHuang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "front-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        #sys.stdout.write('1' if is_speech else '0')\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                # sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                #sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    #if triggered:\n",
    "    #    sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "    #sys.stdout.write('\\n')\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])\n",
    "\n",
    "def VAD(path,ag=1):\n",
    "    audio, sample_rate = read_wave(path)\n",
    "    vad = webrtcvad.Vad(int(ag))\n",
    "    frames = frame_generator(30, audio, sample_rate)\n",
    "    frames = list(frames)\n",
    "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "    \n",
    "    audio_byte = b\"\".join(segments)\n",
    "    return (audio_byte,sample_rate)\n",
    "\n",
    "def byte_to_float(byte):\n",
    "    # byte -> int16(PCM_16) -> float32\n",
    "    return pcm2float(np.frombuffer(byte,dtype=np.int16), dtype='float32')\n",
    "\n",
    "def pcm2float(sig, dtype='float32'):\n",
    "    \"\"\"Convert PCM signal to floating point with a range from -1 to 1.\n",
    "    Use dtype='float32' for single precision.\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig : array_like\n",
    "        Input array, must have integral type.\n",
    "    dtype : data type, optional\n",
    "        Desired (floating point) data type.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Normalized floating point data.\n",
    "    See Also\n",
    "    --------\n",
    "    float2pcm, dtype\n",
    "    \"\"\"\n",
    "    sig = np.asarray(sig)\n",
    "    if sig.dtype.kind not in 'iu':\n",
    "        raise TypeError(\"'sig' must be an array of integers\")\n",
    "    dtype = np.dtype(dtype)\n",
    "    if dtype.kind != 'f':\n",
    "        raise TypeError(\"'dtype' must be a floating point type\")\n",
    "\n",
    "    i = np.iinfo(sig.dtype)\n",
    "    abs_max = 2 ** (i.bits - 1)\n",
    "    offset = i.min + abs_max\n",
    "    return (sig.astype(dtype) - offset) / abs_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-substitute",
   "metadata": {},
   "source": [
    "# Collection and VAD\n",
    "Grab the audio clips and apply VAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constitutional-reverse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path             original  statment  emotion   sex\n",
       "0  Data/Raw Audio/CREMA_D/  1001_DFA_ANG_XX.wav         3    anger  Male\n",
       "1  Data/Raw Audio/CREMA_D/  1001_DFA_DIS_XX.wav         3  disgust  Male\n",
       "2  Data/Raw Audio/CREMA_D/  1001_DFA_FEA_XX.wav         3     fear  Male\n",
       "3  Data/Raw Audio/CREMA_D/  1001_DFA_HAP_XX.wav         3    happy  Male\n",
       "4  Data/Raw Audio/CREMA_D/  1001_DFA_NEU_XX.wav         3  neutral  Male"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legend = pd.read_csv('Data/CSVs/Audio Legend Raw.csv',index_col='Unnamed: 0')\n",
    "legend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggressive-validity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8690 of 8690 complete (100%)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              original                                              audio  \\\n",
       "0  1001_DFA_ANG_XX.wav  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...   \n",
       "0  1001_DFA_DIS_XX.wav  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...   \n",
       "0  1001_DFA_FEA_XX.wav  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...   \n",
       "0  1001_DFA_HAP_XX.wav  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...   \n",
       "0  1001_DFA_NEU_XX.wav  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...   \n",
       "\n",
       "   sample rate  \n",
       "0        16000  \n",
       "0        16000  \n",
       "0        16000  \n",
       "0        16000  \n",
       "0        16000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to save everything in\n",
    "audio = pd.DataFrame()\n",
    "# A list to put any filenames that run into errors\n",
    "error = []\n",
    "\n",
    "count=1\n",
    "for index in legend.index:\n",
    "    try:\n",
    "        entry = legend.loc[index]\n",
    "        track = entry['original']\n",
    "        path = entry['path']\n",
    "        audio_byte,rate = VAD(path+track)\n",
    "        audio = audio.append([[track,audio_byte,rate]])\n",
    "    except:\n",
    "        error.append(track)\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(legend),(count/len(legend))*100),end='\\r')\n",
    "    count+=1\n",
    "    \n",
    "audio.columns = ['original','audio','sample rate']\n",
    "audio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-decimal",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Merge audio with the legend and drop any clips that seem to be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "usual-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path             original  statment  emotion   sex  \\\n",
       "0  Data/Raw Audio/CREMA_D/  1001_DFA_ANG_XX.wav         3    anger  Male   \n",
       "1  Data/Raw Audio/CREMA_D/  1001_DFA_DIS_XX.wav         3  disgust  Male   \n",
       "2  Data/Raw Audio/CREMA_D/  1001_DFA_FEA_XX.wav         3     fear  Male   \n",
       "3  Data/Raw Audio/CREMA_D/  1001_DFA_HAP_XX.wav         3    happy  Male   \n",
       "4  Data/Raw Audio/CREMA_D/  1001_DFA_NEU_XX.wav         3  neutral  Male   \n",
       "\n",
       "                                               audio  sample rate  \n",
       "0  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...        16000  \n",
       "1  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...        16000  \n",
       "2  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...        16000  \n",
       "3  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...        16000  \n",
       "4  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...        16000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = legend.merge(audio,on='original')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advised-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 44 empty tracks\n",
      "There are now 0 empty tracks\n"
     ]
    }
   ],
   "source": [
    "# check for any empty tracks\n",
    "empty_tracks = data[data['audio'] == b\"\"]\n",
    "print('There are currently',len(empty_tracks),'empty tracks')\n",
    "# and drop them\n",
    "data = data.drop(empty_tracks.index)\n",
    "print('There are now',len(data[data['audio'] == b\"\"]),'empty tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-helping",
   "metadata": {},
   "source": [
    "It seems that some of the tracks didn't make it through the VAD because they were too quiet. Iâ€™ll drop these entries because if the VAD couldnâ€™t pick up the audio, I doubt the model will."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-burlington",
   "metadata": {},
   "source": [
    "# Save Files\n",
    "Everything looks good so I'm going to save all the clean audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hourly-institution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7398 of 7398 complete (100%)\r"
     ]
    }
   ],
   "source": [
    "filenames=pd.DataFrame()\n",
    "count = 1\n",
    "for index in data.index:\n",
    "    entry = data.loc[index]\n",
    "    # Save each file with the legend index as the new filename\n",
    "    new_name = 'Clip_%04d.wav' % (index)\n",
    "    path = 'Data/Clean Audio/'+new_name\n",
    "    filenames = filenames.append([[entry['original'],new_name]])\n",
    "    write_wave(path,entry['audio'],entry['sample rate'])\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(data.index),(count/len(data.index))*100),end='\\r')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-massachusetts",
   "metadata": {},
   "source": [
    "Overall, I started with 8877 audio clips and, after the wrangling and filtering, only 8642 remain. Now to save the new filenames in the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "north-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "      <td>Clip_0000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "      <td>Clip_0001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "      <td>Clip_0002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "      <td>Clip_0003.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Raw Audio/CREMA_D/</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "      <td>Clip_0004.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path             original  statment  emotion   sex  \\\n",
       "0  Data/Raw Audio/CREMA_D/  1001_DFA_ANG_XX.wav         3    anger  Male   \n",
       "1  Data/Raw Audio/CREMA_D/  1001_DFA_DIS_XX.wav         3  disgust  Male   \n",
       "2  Data/Raw Audio/CREMA_D/  1001_DFA_FEA_XX.wav         3     fear  Male   \n",
       "3  Data/Raw Audio/CREMA_D/  1001_DFA_HAP_XX.wav         3    happy  Male   \n",
       "4  Data/Raw Audio/CREMA_D/  1001_DFA_NEU_XX.wav         3  neutral  Male   \n",
       "\n",
       "        filename  \n",
       "0  Clip_0000.wav  \n",
       "1  Clip_0001.wav  \n",
       "2  Clip_0002.wav  \n",
       "3  Clip_0003.wav  \n",
       "4  Clip_0004.wav  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organize filenames\n",
    "filenames.columns = ['original','filename']\n",
    "# and merge on the old names\n",
    "new_legend = legend.merge(filenames,how='left',on='original')\n",
    "\n",
    "new_legend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "classified-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect now save!\n",
    "new_legend.to_csv('Data/CSVs/Audio Legend Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-prompt",
   "metadata": {},
   "source": [
    "### Example Clip\n",
    "Play a random audio clip from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efficient-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original    1026_IOM_NEU_XX.wav\n",
      "statment                      5\n",
      "emotion                 neutral\n",
      "sex                        Male\n",
      "Name: 2057, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# select a random clip\n",
    "n = np.random.permutation(data.index)[0]\n",
    "example = data.loc[n]\n",
    "\n",
    "# print info about the clip\n",
    "print(example.loc[['original','statment','emotion','sex']])\n",
    "\n",
    "# play audio\n",
    "example_audio = byte_to_float(example['audio'])\n",
    "example_srate = example['sample rate']\n",
    "sd.play(example_audio, example_srate)\n",
    "status = sd.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
