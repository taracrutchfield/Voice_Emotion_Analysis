{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "diverse-software",
   "metadata": {},
   "source": [
    "# Audio Cleaning\n",
    "With my handy new legend, I can easily go and select all the audio clips I want. Iâ€™ll be applying a voice activity detection filter (VAD) on each clip to help remove some of the background sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Modules\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import webrtcvad\n",
    "# General Modules\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-warren",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Audio processing in python is a relativley new thing for me so I \"found inspiration\" (aka tweeked snippets of code) from the projects of others.\n",
    "- VAD by [John Wiseman](https://github.com/wiseman)\n",
    "- Byte to numpy array conversion by [HudsonHuang](https://gist.github.com/HudsonHuang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interior-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        #sys.stdout.write('1' if is_speech else '0')\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                # sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                #sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    #if triggered:\n",
    "    #    sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "    #sys.stdout.write('\\n')\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])\n",
    "\n",
    "def VAD(path,ag=1):\n",
    "    audio, sample_rate = read_wave(path)\n",
    "    vad = webrtcvad.Vad(int(ag))\n",
    "    frames = frame_generator(30, audio, sample_rate)\n",
    "    frames = list(frames)\n",
    "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "    \n",
    "    audio_byte = b\"\".join(segments)\n",
    "    return (audio_byte,sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-pennsylvania",
   "metadata": {},
   "source": [
    "# Collection and VAD\n",
    "Grab the audio clips and apply VAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approximate-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   path      20 non-null     object\n",
      " 1   original  20 non-null     object\n",
      " 2   statment  20 non-null     int64 \n",
      " 3   emotion   20 non-null     object\n",
      " 4   sex       20 non-null     object\n",
      " 5   race      12 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "legend = pd.read_csv('Data/CSVs/Audio Legend Raw.csv',index_col='Unnamed: 0')\n",
    "legend.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "european-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 of 20 complete (5%)\r",
      "   2 of 20 complete (10%)\r",
      "   3 of 20 complete (15%)\r",
      "   4 of 20 complete (20%)\r",
      "   5 of 20 complete (25%)\r",
      "   6 of 20 complete (30%)\r",
      "   7 of 20 complete (35%)\r",
      "   8 of 20 complete (40%)\r",
      "   9 of 20 complete (45%)\r",
      "  10 of 20 complete (50%)\r",
      "  11 of 20 complete (55%)\r",
      "  12 of 20 complete (60%)\r",
      "  13 of 20 complete (65%)\r",
      "  14 of 20 complete (70%)\r",
      "  15 of 20 complete (75%)\r",
      "  16 of 20 complete (80%)\r",
      "  17 of 20 complete (85%)\r",
      "  18 of 20 complete (90%)\r",
      "  19 of 20 complete (95%)\r",
      "  20 of 20 complete (100%)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_IEO_DIS_HI.wav</td>\n",
       "      <td>b'?\\xffe\\xffo\\xff}\\xff\\x7f\\xff\\xa7\\xff\\xc0\\xff...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_IOM_FEA_XX.wav</td>\n",
       "      <td>b'\\x8d\\xfd\\xd2\\xfd\\xe6\\xfd\\x03\\xfe\\xf4\\xfd8\\xf...</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_ITH_HAP_XX.wav</td>\n",
       "      <td>b'\\x0e\\x00\\x03\\x00\\x0c\\x00\\x18\\x00\\x01\\x00\\xdd...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_ITS_NEU_XX.wav</td>\n",
       "      <td>b'\\xb2\\x00\\xbd\\x00|\\x00T\\x005\\x00\\x94\\x00~\\x00...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  original                                              audio  \\\n",
       "index                                                                           \n",
       "0      1001_DFA_ANG_XX.wav  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...   \n",
       "1      1001_IEO_DIS_HI.wav  b'?\\xffe\\xffo\\xff}\\xff\\x7f\\xff\\xa7\\xff\\xc0\\xff...   \n",
       "2      1001_IOM_FEA_XX.wav  b'\\x8d\\xfd\\xd2\\xfd\\xe6\\xfd\\x03\\xfe\\xf4\\xfd8\\xf...   \n",
       "3      1001_ITH_HAP_XX.wav  b'\\x0e\\x00\\x03\\x00\\x0c\\x00\\x18\\x00\\x01\\x00\\xdd...   \n",
       "4      1001_ITS_NEU_XX.wav  b'\\xb2\\x00\\xbd\\x00|\\x00T\\x005\\x00\\x94\\x00~\\x00...   \n",
       "\n",
       "      sample rate  time  \n",
       "index                    \n",
       "0           16000  1.68  \n",
       "1           16000  1.38  \n",
       "2           16000  2.28  \n",
       "3           16000  1.80  \n",
       "4           16000  1.86  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to save everything in\n",
    "audio = pd.DataFrame(columns=['index','original','audio','sample rate','time'])\n",
    "\n",
    "indices = legend.index\n",
    "for count,index in enumerate(indices,start=1):\n",
    "    entry = legend.loc[index]\n",
    "    track = entry['original']\n",
    "    path = entry['path']\n",
    "    try:\n",
    "        audio_byte,rate = VAD(path+track)\n",
    "        time = (len(audio_byte)/2)/rate\n",
    "        # if audio_byte is empty, try less rigorous VAD\n",
    "        if audio_byte == b'':\n",
    "            audio_byte,rate = VAD(path+track,ag=0)\n",
    "            time = (len(audio_byte)/2)/rate\n",
    "            # if its still empty, input nan\n",
    "            if audio_byte == b'':\n",
    "                audio_byte,rate,time = np.nan,np.nan,np.nan\n",
    "    except:\n",
    "        audio_byte,rate = np.nan,np.nan\n",
    "    audio = audio.append({'index':index,'original':track,'audio':audio_byte,'sample rate':rate,\n",
    "                          'time':time},ignore_index=True)\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(indices),(count/len(indices))*100),end='\\r')\n",
    "\n",
    "audio = audio.set_index('index')    \n",
    "audio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-spine",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Merge audio with the legend and drop any clips that seem to be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confident-webster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_IEO_DIS_HI.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>b'?\\xffe\\xffo\\xff}\\xff\\x7f\\xff\\xa7\\xff\\xc0\\xff...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_IOM_FEA_XX.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>b'\\x8d\\xfd\\xd2\\xfd\\xe6\\xfd\\x03\\xfe\\xf4\\xfd8\\xf...</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_ITH_HAP_XX.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>b'\\x0e\\x00\\x03\\x00\\x0c\\x00\\x18\\x00\\x01\\x00\\xdd...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_ITS_NEU_XX.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>b'\\xb2\\x00\\xbd\\x00|\\x00T\\x005\\x00\\x94\\x00~\\x00...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path             original  statment  emotion   sex  \\\n",
       "0  Data/Audio/Raw/CREMA_D/  1001_DFA_ANG_XX.wav         3    anger  Male   \n",
       "1  Data/Audio/Raw/CREMA_D/  1001_IEO_DIS_HI.wav         4  disgust  Male   \n",
       "2  Data/Audio/Raw/CREMA_D/  1001_IOM_FEA_XX.wav         5     fear  Male   \n",
       "3  Data/Audio/Raw/CREMA_D/  1001_ITH_HAP_XX.wav         6    happy  Male   \n",
       "4  Data/Audio/Raw/CREMA_D/  1001_ITS_NEU_XX.wav         7  neutral  Male   \n",
       "\n",
       "        race                                              audio sample rate  \\\n",
       "0  Caucasian  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...       16000   \n",
       "1  Caucasian  b'?\\xffe\\xffo\\xff}\\xff\\x7f\\xff\\xa7\\xff\\xc0\\xff...       16000   \n",
       "2  Caucasian  b'\\x8d\\xfd\\xd2\\xfd\\xe6\\xfd\\x03\\xfe\\xf4\\xfd8\\xf...       16000   \n",
       "3  Caucasian  b'\\x0e\\x00\\x03\\x00\\x0c\\x00\\x18\\x00\\x01\\x00\\xdd...       16000   \n",
       "4  Caucasian  b'\\xb2\\x00\\xbd\\x00|\\x00T\\x005\\x00\\x94\\x00~\\x00...       16000   \n",
       "\n",
       "   time  \n",
       "0  1.68  \n",
       "1  1.38  \n",
       "2  2.28  \n",
       "3  1.80  \n",
       "4  1.86  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = legend.merge(audio)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-confidence",
   "metadata": {},
   "source": [
    "Check for the tracks that didn't make it through VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "final-console",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tracks couldnt be filtered\n",
      "\n",
      "Emotions\n",
      "Series([], Name: emotion, dtype: int64)\n",
      "\n",
      "Actor Gender\n",
      "Series([], Name: sex, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "tracks_na = data[data['audio'].isna()]\n",
    "print('%d tracks couldnt be filtered\\n' % len(tracks_na))\n",
    "print('Emotions')\n",
    "print(tracks_na['emotion'].value_counts())\n",
    "print('\\nActor Gender')\n",
    "print(tracks_na['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-shield",
   "metadata": {},
   "source": [
    "Taking a look at some of these tracks, it appears that the voices in the audio clips were too quiet to pick up. This seems to be most common in the `sad` voice clips, with a majority of the actors being women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "personal-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the empty clips\n",
    "data = data.drop(tracks_na.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-submission",
   "metadata": {},
   "source": [
    "# Save Files\n",
    "Save all the clean audio clips in the folder `Clean Audio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elder-arthur",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 of 20 complete (5%)\r",
      "   2 of 20 complete (10%)\r",
      "   3 of 20 complete (15%)\r",
      "   4 of 20 complete (20%)\r",
      "   5 of 20 complete (25%)\r",
      "   6 of 20 complete (30%)\r",
      "   7 of 20 complete (35%)\r",
      "   8 of 20 complete (40%)\r",
      "   9 of 20 complete (45%)\r",
      "  10 of 20 complete (50%)\r",
      "  11 of 20 complete (55%)\r",
      "  12 of 20 complete (60%)\r",
      "  13 of 20 complete (65%)\r",
      "  14 of 20 complete (70%)\r",
      "  15 of 20 complete (75%)\r",
      "  16 of 20 complete (80%)\r",
      "  17 of 20 complete (85%)\r",
      "  18 of 20 complete (90%)\r",
      "  19 of 20 complete (95%)\r",
      "  20 of 20 complete (100%)\r"
     ]
    }
   ],
   "source": [
    "filenames=pd.DataFrame()\n",
    "\n",
    "indices = data.index\n",
    "for count,index in enumerate(indices,start=1):\n",
    "    entry = data.loc[index]\n",
    "    # Save each file with the legend index as the new filename\n",
    "    new_name = 'Clip_%04d.wav' % (index)\n",
    "    path = 'Data/Audio/Clean/'+new_name\n",
    "    filenames = filenames.append([[entry['original'],new_name]])\n",
    "    write_wave(path,entry['audio'],entry['sample rate'])\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(indices),(count/len(indices))*100),end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-accommodation",
   "metadata": {},
   "source": [
    "Merge the new filenames with the old filenames and save as the new legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "administrative-cathedral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>time</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.68</td>\n",
       "      <td>Clip_0000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_IEO_DIS_HI.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.38</td>\n",
       "      <td>Clip_0001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_IOM_FEA_XX.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2.28</td>\n",
       "      <td>Clip_0002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_ITH_HAP_XX.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.80</td>\n",
       "      <td>Clip_0003.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_ITS_NEU_XX.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.86</td>\n",
       "      <td>Clip_0004.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              original  statment  emotion   sex       race  time  \\\n",
       "0  1001_DFA_ANG_XX.wav         3    anger  Male  Caucasian  1.68   \n",
       "1  1001_IEO_DIS_HI.wav         4  disgust  Male  Caucasian  1.38   \n",
       "2  1001_IOM_FEA_XX.wav         5     fear  Male  Caucasian  2.28   \n",
       "3  1001_ITH_HAP_XX.wav         6    happy  Male  Caucasian  1.80   \n",
       "4  1001_ITS_NEU_XX.wav         7  neutral  Male  Caucasian  1.86   \n",
       "\n",
       "        filename  \n",
       "0  Clip_0000.wav  \n",
       "1  Clip_0001.wav  \n",
       "2  Clip_0002.wav  \n",
       "3  Clip_0003.wav  \n",
       "4  Clip_0004.wav  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organize filenames\n",
    "filenames.columns = ['original','filename']\n",
    "# and merge on the old names\n",
    "new_legend = data.merge(filenames,how='left',on='original')\n",
    "new_legend = new_legend.drop(columns=['path','audio','sample rate'])\n",
    "\n",
    "new_legend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "african-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect now save!\n",
    "new_legend.to_csv('Data/CSVs/Audio Legend Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-copper",
   "metadata": {},
   "source": [
    "### Example Clip\n",
    "Play a random audio clip from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "romance-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename    Clip_0010.wav\n",
      "statment               12\n",
      "emotion              fear\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# select a random clip\n",
    "example = np.random.permutation(new_legend)[0]\n",
    "example = pd.Series(dict(zip(new_legend.columns,example)))\n",
    "\n",
    "# print info about the clip\n",
    "print(example[['filename','statment','emotion']])\n",
    "\n",
    "# play audio\n",
    "clip, samplerate = sf.read('Data/Audio/Clean/'+example['filename'])\n",
    "sd.play(clip, samplerate)\n",
    "status = sd.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
