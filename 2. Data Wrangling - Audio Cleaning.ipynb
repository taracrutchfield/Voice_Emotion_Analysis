{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fewer-links",
   "metadata": {},
   "source": [
    "# Audio Cleaning\n",
    "With my handy new legend, I can easily go and select all the audio clips I want. Iâ€™ll be applying a voice activity detection filter (VAD) on each clip to help remove some of the background sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stable-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Modules\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import webrtcvad\n",
    "# General Modules\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-original",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Audio processing in python is a relativley new thing for me so I \"found inspiration\" (aka tweeked snippets of code) from the projects of others.\n",
    "- VAD by [John Wiseman](https://github.com/wiseman)\n",
    "- Byte to numpy array conversion by [HudsonHuang](https://gist.github.com/HudsonHuang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        #sys.stdout.write('1' if is_speech else '0')\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                # sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                #sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    #if triggered:\n",
    "    #    sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
    "    #sys.stdout.write('\\n')\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])\n",
    "\n",
    "def VAD(path,ag=1):\n",
    "    audio, sample_rate = read_wave(path)\n",
    "    vad = webrtcvad.Vad(int(ag))\n",
    "    frames = frame_generator(30, audio, sample_rate)\n",
    "    frames = list(frames)\n",
    "    segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "    \n",
    "    audio_byte = b\"\".join(segments)\n",
    "    return (audio_byte,sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-fruit",
   "metadata": {},
   "source": [
    "# Collection and VAD\n",
    "Grab the audio clips and apply VAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ancient-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8882 entries, 0 to 8881\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   path       8882 non-null   object\n",
      " 1   original   8882 non-null   object\n",
      " 2   actorid    8882 non-null   int64 \n",
      " 3   statment   8882 non-null   int64 \n",
      " 4   emotion    8882 non-null   object\n",
      " 5   sex        8882 non-null   object\n",
      " 6   race       7442 non-null   object\n",
      " 7   ethnicity  7442 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 624.5+ KB\n"
     ]
    }
   ],
   "source": [
    "legend = pd.read_csv('Data/CSVs/Audio Legend Raw.csv',index_col='Unnamed: 0')\n",
    "legend.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "single-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8882 of 8882 complete (100%)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  original                                              audio  \\\n",
       "index                                                                           \n",
       "0      1001_DFA_ANG_XX.wav  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...   \n",
       "1      1001_DFA_DIS_XX.wav  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...   \n",
       "2      1001_DFA_FEA_XX.wav  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...   \n",
       "3      1001_DFA_HAP_XX.wav  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...   \n",
       "4      1001_DFA_NEU_XX.wav  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...   \n",
       "\n",
       "      sample rate  time  \n",
       "index                    \n",
       "0           16000  1.68  \n",
       "1           16000  1.50  \n",
       "2           16000  1.26  \n",
       "3           16000  1.29  \n",
       "4           16000  1.44  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to save everything in\n",
    "audio = pd.DataFrame(columns=['index','original','audio','sample rate','time'])\n",
    "\n",
    "indices = legend.index\n",
    "for count,index in enumerate(indices,start=1):\n",
    "    entry = legend.loc[index]\n",
    "    track = entry['original']\n",
    "    path = entry['path']\n",
    "    try:\n",
    "        audio_byte,rate = VAD(path+track)\n",
    "        time = (len(audio_byte)/2)/rate\n",
    "        # if audio_byte is empty, try less rigorous VAD\n",
    "        if audio_byte == b'':\n",
    "            audio_byte,rate = VAD(path+track,ag=0)\n",
    "            time = (len(audio_byte)/2)/rate\n",
    "            # if its still empty, input nan\n",
    "            if audio_byte == b'':\n",
    "                audio_byte,rate,time = np.nan,np.nan,np.nan\n",
    "    except:\n",
    "        audio_byte,rate = np.nan,np.nan\n",
    "    audio = audio.append({'index':index,'original':track,'audio':audio_byte,'sample rate':rate,\n",
    "                          'time':time},ignore_index=True)\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(indices),(count/len(indices))*100),end='\\r')\n",
    "\n",
    "audio = audio.set_index('index')    \n",
    "audio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-sterling",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Merge audio with the legend and drop any clips that seem to be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "biblical-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "      <th>actorid</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>audio</th>\n",
       "      <th>sample rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Audio/Raw/CREMA_D/</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path             original  actorid  statment  emotion  \\\n",
       "0  Data/Audio/Raw/CREMA_D/  1001_DFA_ANG_XX.wav     1001         3    anger   \n",
       "1  Data/Audio/Raw/CREMA_D/  1001_DFA_DIS_XX.wav     1001         3  disgust   \n",
       "2  Data/Audio/Raw/CREMA_D/  1001_DFA_FEA_XX.wav     1001         3     fear   \n",
       "3  Data/Audio/Raw/CREMA_D/  1001_DFA_HAP_XX.wav     1001         3    happy   \n",
       "4  Data/Audio/Raw/CREMA_D/  1001_DFA_NEU_XX.wav     1001         3  neutral   \n",
       "\n",
       "    sex       race     ethnicity  \\\n",
       "0  Male  Caucasian  Not Hispanic   \n",
       "1  Male  Caucasian  Not Hispanic   \n",
       "2  Male  Caucasian  Not Hispanic   \n",
       "3  Male  Caucasian  Not Hispanic   \n",
       "4  Male  Caucasian  Not Hispanic   \n",
       "\n",
       "                                               audio sample rate  time  \n",
       "0  b'\\xae\\x00\\xa9\\x00\\xb1\\x00\\xac\\x00\\xa8\\x00\\xad...       16000  1.68  \n",
       "1  b'C\\x00\\xf3\\xff\\xdb\\xff]\\x00\\xa8\\x00n\\x00\\x1b\\...       16000  1.50  \n",
       "2  b'\\xd2\\x00\\xa9\\x00\\xf1\\x00\\x8d\\x00\\xe5\\x00\\xf6...       16000  1.26  \n",
       "3  b'4\\xffP\\xff\\x0e\\xff\\xb8\\xfe\\xb3\\xfe\\'\\xff1\\xf...       16000  1.29  \n",
       "4  b'\\xe5\\xfe\\xf4\\xfe\\xef\\xfe\\x06\\xff\\x19\\xff\\x14...       16000  1.44  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = legend.merge(audio)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-hands",
   "metadata": {},
   "source": [
    "Check for the tracks that didn't make it through VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compressed-persian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 tracks couldnt be filtered\n",
      "\n",
      "Emotions\n",
      "sad          30\n",
      "disgust       3\n",
      "calm          2\n",
      "fear          2\n",
      "surprised     1\n",
      "neutral       1\n",
      "happy         1\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Actor Gender\n",
      "Female    25\n",
      "Male      15\n",
      "Name: sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tracks_na = data[data['audio'].isna()]\n",
    "print('%d tracks couldnt be filtered\\n' % len(tracks_na))\n",
    "print('Emotions')\n",
    "print(tracks_na['emotion'].value_counts())\n",
    "print('\\nActor Gender')\n",
    "print(tracks_na['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-timber",
   "metadata": {},
   "source": [
    "Taking a look at some of these tracks, it appears that the voices in the audio clips were too quiet to pick up. This seems to be most common in the `sad` voice clips, with a majority of the actors being women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equivalent-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the empty clips\n",
    "data = data.drop(tracks_na.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-barcelona",
   "metadata": {},
   "source": [
    "# Save Files\n",
    "Save all the clean audio clips in the folder `Clean Audio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-sapphire",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8842 of 8842 complete (100%)\r"
     ]
    }
   ],
   "source": [
    "filenames=pd.DataFrame()\n",
    "\n",
    "indices = data.index\n",
    "for count,index in enumerate(indices,start=1):\n",
    "    entry = data.loc[index]\n",
    "    # Save each file with the legend index as the new filename\n",
    "    new_name = 'Clip_%04d.wav' % (index)\n",
    "    path = 'Data/Audio/Clean/'+new_name\n",
    "    filenames = filenames.append([[entry['original'],new_name]])\n",
    "    write_wave(path,entry['audio'],entry['sample rate'])\n",
    "    # progress bar\n",
    "    print('%4d of %d complete (%d%%)' % (count,len(indices),(count/len(indices))*100),end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-budget",
   "metadata": {},
   "source": [
    "Merge the new filenames with the old filenames and save as the new legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abandoned-avenue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>actorid</th>\n",
       "      <th>statment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>time</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>1.68</td>\n",
       "      <td>Clip_0000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Clip_0001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>fear</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>1.26</td>\n",
       "      <td>Clip_0002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>1.29</td>\n",
       "      <td>Clip_0003.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "      <td>1.44</td>\n",
       "      <td>Clip_0004.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              original  actorid  statment  emotion   sex       race  \\\n",
       "0  1001_DFA_ANG_XX.wav     1001         3    anger  Male  Caucasian   \n",
       "1  1001_DFA_DIS_XX.wav     1001         3  disgust  Male  Caucasian   \n",
       "2  1001_DFA_FEA_XX.wav     1001         3     fear  Male  Caucasian   \n",
       "3  1001_DFA_HAP_XX.wav     1001         3    happy  Male  Caucasian   \n",
       "4  1001_DFA_NEU_XX.wav     1001         3  neutral  Male  Caucasian   \n",
       "\n",
       "      ethnicity  time       filename  \n",
       "0  Not Hispanic  1.68  Clip_0000.wav  \n",
       "1  Not Hispanic  1.50  Clip_0001.wav  \n",
       "2  Not Hispanic  1.26  Clip_0002.wav  \n",
       "3  Not Hispanic  1.29  Clip_0003.wav  \n",
       "4  Not Hispanic  1.44  Clip_0004.wav  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organize filenames\n",
    "filenames.columns = ['original','filename']\n",
    "# and merge on the old names\n",
    "new_legend = data.merge(filenames,how='left',on='original')\n",
    "new_legend = new_legend.drop(columns=['path','audio','sample rate'])\n",
    "\n",
    "new_legend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enabling-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect now save!\n",
    "new_legend.to_csv('Data/CSVs/Audio Legend Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-percentage",
   "metadata": {},
   "source": [
    "### Example Clip\n",
    "Play a random audio clip from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bored-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename    Clip_6015.wav\n",
      "statment                9\n",
      "emotion              fear\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# select a random clip\n",
    "example = np.random.permutation(new_legend)[0]\n",
    "example = pd.Series(dict(zip(new_legend.columns,example)))\n",
    "\n",
    "# print info about the clip\n",
    "print(example[['filename','statment','emotion']])\n",
    "\n",
    "# play audio\n",
    "clip, samplerate = sf.read('Data/Audio/Clean/'+example['filename'])\n",
    "sd.play(clip, samplerate)\n",
    "status = sd.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
